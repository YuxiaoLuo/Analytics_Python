{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7916152f",
   "metadata": {},
   "source": [
    "# API vs Web Craping\n",
    "\n",
    "- Extracting informaiton from websites can be done via scraping or by working with the site API if there is one \n",
    "    - working with APIs is preferable \n",
    "    - Comparison of Web Scraping vs. API for Hacker News\n",
    "    \n",
    "## RAPTOR \n",
    "Raptor means: Review - Access - Parse - Transorm -stORe.\n",
    "\n",
    "| |Web Server | Web Server + API|\n",
    "|:---|:---------|:-----------|\n",
    "|Review | HTML structure (tags, attributes, etc.) | Parameters and structure from documentation|\n",
    "\n",
    "\n",
    "### Hacker News Example\n",
    "[Hacker News](https://news.ycombinator.com/) is a social \n",
    "- It also offers an API providing structured, JSON-formatted results\n",
    "    - Base URL: https://hacker-news.firebaseio.com/v0\n",
    " \n",
    "- See explanation and documentation at: http://github.com/HackerNews/API\n",
    "\n",
    "- The new Python \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423bbec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: adpated from Broucke & Baessen (Chp. b9)\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# articles is an list that will hold info about each article \n",
    "articles = []\n",
    "\n",
    "url = 'http://news.ycombinator.com/news'\n",
    "r = requests.get(url)\n",
    "html_soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "for item in html_soup.find_all('tr', class = 'athing'):\n",
    "    item_a = item.find('a', class_ = 'storylink')\n",
    "    item_link = item_a.get('href') if item_a else None\n",
    "    next_row = item.find_next_sibling('tr')\n",
    "    item_score = next_row.find('span', class = 'score')\n",
    "    item_score = item_score.get_text(strip = True) if item_score else '0 points'\n",
    "# append the article info \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74158900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "articles = []\n",
    "url = 'https://hacker-news.firebaseio.com/v0'\n",
    "top_stories = requests.get(url + '/topstories.json').json()\n",
    "\n",
    "print(len(top_stories))\n",
    "type(top_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c5b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for story_id in top_stories:\n",
    "    story_url = url + '/item/{}.json'.format(story_id)\n",
    "    print(\"Fetching:\", story_url)\n",
    "    r = requests.get(story_url)\n",
    "    story_dict = r.json()\n",
    "    articles.append(story_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed862f32",
   "metadata": {},
   "source": [
    "### How to retrieve the top 10 stories \n",
    "First method: query encoding in API requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2b274af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29110444, 29108648, 29106824, 29110419, 29109092, 29109492, 29110673, 29104047, 29110514, 29109655]\n"
     ]
    }
   ],
   "source": [
    "url10 = 'https://hacker-news.firebaseio.com/v0/topstories.json?limitToFirst=10&orderBy=\"$key\"'\n",
    "ten_top_stories = requests.get(url10).json()\n",
    "print(ten_top_stories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c07a90c",
   "metadata": {},
   "source": [
    "The other approach consists of defining a dict and pass it as a parameter\n",
    "   - this along with the headers allows to make a more specific request to an API\n",
    "   - it's recommended when developer key is needed \n",
    "   \n",
    "### Specific API requests\n",
    " \n",
    "- To make the API requests more specific, use headers and parameters in the request\n",
    "     - Headers\n",
    "     - Parameters are like filters to modify the scope of the request\n",
    "         - check API documentation\n",
    "         \n",
    "- Reddit Example\n",
    "     - With a user-agent header "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f2f91d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECO 1001 Professor Thoughts: Andrew Green, Ernestro Garica, or Somayeh Ahmadi?\n",
      "What does staff mean under instructor?\n",
      "Mitchell Cohen for POL 1101?\n",
      "Opinions and thoughts of the class\n",
      "Switching to Operations Management\n"
     ]
    }
   ],
   "source": [
    "# Scrap the news in Reddit\n",
    "# Code is adapted from the website: \n",
    "# http://towardsdatascience.com/a-beginners-guide-to-accessing-data-withweb-apis-using-python-23d262181467\n",
    "import requests, json\n",
    "\n",
    "payload = {\n",
    "    'limit': 5,\n",
    "    't': 'hot'\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'User-agent': 'Reddit bot 1.0'\n",
    "}\n",
    "\n",
    "endpoint = 'http://www.reddit.com/r/news/top.json'\n",
    "# can try other channel\n",
    "# endpoint = 'http://www.reddit.com/r/funny/top.json'\n",
    "endpoint = 'http://www.reddit.com/r/Baruch/new.json'\n",
    "\n",
    "r = requests.get(endpoint, headers = headers, params = payload)\n",
    "r = json.loads(r.content)\n",
    "\n",
    "# import pprint\n",
    "# pprint.pprint(r)\n",
    "\n",
    "for sub in (r['data']['children']):\n",
    "    title = sub['data']['title']\n",
    "    print(title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a472ec0",
   "metadata": {},
   "source": [
    "### Authenticatoin for News API\n",
    "\n",
    "News API is a simple HTTP REST API for searching and retrieving live articles from various sources\n",
    "\n",
    "- Get your secret API key\n",
    "    - Go to: https://newsapi.org/docs/get-started\n",
    "\n",
    "- MY API key: [*****************************************](e66483a4f4b0480a9a29a4fac0586469)\n",
    "\n",
    "- Read the terms of service: https://newsapi.org/terms\n",
    "    - attribution: The attribution should preferrably be a hyperlink to https://newsapi.org with the text \"Powered by News API\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a19c23d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'newsapi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-30f2852ff3bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnewsapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNewsApiClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnewsapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNewsApiClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'e66483a4f4b0480a9a29a4fac0586469'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# /v2/top-headlines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'newsapi'"
     ]
    }
   ],
   "source": [
    "from newsapi import NewsApiClient\n",
    "# Init\n",
    "newsapi = NewsApiClient(api_key='e66483a4f4b0480a9a29a4fac0586469')\n",
    "\n",
    "# /v2/top-headlines\n",
    "top_headlines = newsapi.get_top_headlines(q='bitcoin',\n",
    "                                          sources='bbc-news,the-verge',\n",
    "                                          category='business',\n",
    "                                          language='en',\n",
    "                                          country='us')\n",
    "# /v2/everything\n",
    "all_articles = newsapi.get_everything(q='bitcoin',\n",
    "                                      sources='bbc-news,the-verge',\n",
    "                                      domains='bbc.co.uk,techcrunch.com',\n",
    "                                      from_param='2017-12-01',\n",
    "                                      to='2017-12-12',\n",
    "                                      language='en',\n",
    "                                      sort_by='relevancy',\n",
    "                                      page=2)\n",
    "\n",
    "# /v2/top-headlines/sources\n",
    "\n",
    "sources = newsapi.get_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88cfc3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Covid: Record German cases as WHO warns of Europe deaths 56\n",
      "2 Climate change: Facebook fails to flag denial, study finds 58\n",
      "3 Ahmaud Arbery: Nearly all-white jury chosen in black jogger murder trial 72\n",
      "4 How a medieval English law affects the US gun control debate 60\n",
      "5 LA 'jetpack man' was probably a balloon 39\n",
      "6 'I hope people would be more sceptical today' - Knox 52\n",
      "7 First pill to treat Covid gets approval in UK 45\n",
      "8 High-risk Covid gene more common in South Asians 48\n",
      "9 Trump-Russia Steele dossier analyst charged with lying to FBI 61\n",
      "10 COP26: Indonesia criticises 'unfair' deal to end deforestation 62\n"
     ]
    }
   ],
   "source": [
    "# Ex.4\n",
    "# source: https://www.geeksforgeeks.org/fetching-top-news-using-news-api/\n",
    "# BBC news api with authorization header and parameters\n",
    "\n",
    "import requests \n",
    "\n",
    "# headers to store the API key\n",
    "headers = {'Authorization': 'e66483a4f4b0480a9a29a4fac0586469'}\n",
    "query_params = {\n",
    "      \"source\": \"bbc-news\",\n",
    "      \"sortBy\": \"top\"\n",
    "}\n",
    "main_url = \" https://newsapi.org/v1/articles\"\n",
    " \n",
    "# fetching data in json format\n",
    "res = requests.get(main_url, headers = headers, params=query_params)\n",
    "open_bbc_page = res.json()\n",
    " \n",
    "# getting all articles in a string article\n",
    "article = open_bbc_page[\"articles\"]\n",
    " \n",
    "# empty list to hold all trending news\n",
    "results = []\n",
    "     \n",
    "for ar in article:\n",
    "    results.append(ar[\"title\"])\n",
    "\n",
    "# printing all trending news       \n",
    "for i in range(len(results)):            \n",
    "    print(i + 1, results[i], len(results[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e3979cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package requests:\n",
      "\n",
      "NAME\n",
      "    requests\n",
      "\n",
      "DESCRIPTION\n",
      "    Requests HTTP Library\n",
      "    ~~~~~~~~~~~~~~~~~~~~~\n",
      "    \n",
      "    Requests is an HTTP library, written in Python, for human beings.\n",
      "    Basic GET usage:\n",
      "    \n",
      "       >>> import requests\n",
      "       >>> r = requests.get('https://www.python.org')\n",
      "       >>> r.status_code\n",
      "       200\n",
      "       >>> b'Python is a programming language' in r.content\n",
      "       True\n",
      "    \n",
      "    ... or POST:\n",
      "    \n",
      "       >>> payload = dict(key1='value1', key2='value2')\n",
      "       >>> r = requests.post('https://httpbin.org/post', data=payload)\n",
      "       >>> print(r.text)\n",
      "       {\n",
      "         ...\n",
      "         \"form\": {\n",
      "           \"key1\": \"value1\",\n",
      "           \"key2\": \"value2\"\n",
      "         },\n",
      "         ...\n",
      "       }\n",
      "    \n",
      "    The other HTTP methods are supported - see `requests.api`. Full documentation\n",
      "    is at <https://requests.readthedocs.io>.\n",
      "    \n",
      "    :copyright: (c) 2017 by Kenneth Reitz.\n",
      "    :license: Apache 2.0, see LICENSE for more details.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    __version__\n",
      "    _internal_utils\n",
      "    adapters\n",
      "    api\n",
      "    auth\n",
      "    certs\n",
      "    compat\n",
      "    cookies\n",
      "    exceptions\n",
      "    help\n",
      "    hooks\n",
      "    models\n",
      "    packages\n",
      "    sessions\n",
      "    status_codes\n",
      "    structures\n",
      "    utils\n",
      "\n",
      "FUNCTIONS\n",
      "    check_compatibility(urllib3_version, chardet_version)\n",
      "\n",
      "DATA\n",
      "    __author_email__ = 'me@kennethreitz.org'\n",
      "    __build__ = 140545\n",
      "    __cake__ = '‚ú® üç∞ ‚ú®'\n",
      "    __copyright__ = 'Copyright 2020 Kenneth Reitz'\n",
      "    __description__ = 'Python HTTP for Humans.'\n",
      "    __license__ = 'Apache 2.0'\n",
      "    __title__ = 'requests'\n",
      "    __url__ = 'https://requests.readthedocs.io'\n",
      "    codes = <lookup 'status_codes'>\n",
      "\n",
      "VERSION\n",
      "    2.25.1\n",
      "\n",
      "AUTHOR\n",
      "    Kenneth Reitz\n",
      "\n",
      "FILE\n",
      "    c:\\users\\yuxiao luo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\requests\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(requests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7916152f",
   "metadata": {},
   "source": [
    "# API vs Web Craping\n",
    "\n",
    "- Extracting informaiton from websites can be done via scraping or by working with the site API if there is one \n",
    "    - working with APIs is preferable \n",
    "    - Comparison of Web Scraping vs. API for Hacker News\n",
    "    \n",
    "## RAPTOR \n",
    "Raptor means: Review - Access - Parse - Transorm -Store.\n",
    "\n",
    "| |Web Server | Web Server + API|\n",
    "|:---|:---------|:-----------|\n",
    "|Review | HTML structure (tags, attributes, etc.) | Parameters and structure from documentation|\n",
    "\n",
    "\n",
    "### Hacker News Example\n",
    "[Hacker News](https://news.ycombinator.com/) is a social Hacker News is a social news website focusing on computer science and entrepreneurship. It is run by the investment fund and startup incubator Y Combinator. In general, content that can be submitted is defined as \"anything that gratifies one's intellectual curiosity.\"\n",
    "\n",
    "- It also offers an API providing structured, JSON-formatted results\n",
    "    - Base URL: https://hacker-news.firebaseio.com/v0\n",
    " \n",
    "- See explanation and documentation at: http://github.com/HackerNews/API\n",
    "\n",
    "- The new Python \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb246fc",
   "metadata": {},
   "source": [
    "1. First, let's try to scrape all the article title, link, and score from https://news.ycombinator.com/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "423bbec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': 'Software Engineering at Google (abseil.io)', 'Link': 'https://abseil.io/resources/swe-book/html/toc.html', 'Score': '24 points'}\n",
      "{'Title': 'Analysis of the data job market using HN job posts (emiruz.com)', 'Link': 'https://emiruz.com/post/2023-08-12-data-jobs/', 'Score': '22 points'}\n",
      "{'Title': 'The 2002 Überlingen midair collision (admiralcloudberg.medium.com)', 'Link': 'https://admiralcloudberg.medium.com/tears-in-the-rain-the-2002-%C3%BCberlingen-midair-collision-591232d0c51e', 'Score': '45 points'}\n",
      "{'Title': 'How to run a miserable code review (badsoftwareadvice.substack.com)', 'Link': 'https://badsoftwareadvice.substack.com/p/how-to-run-a-miserable-code-review', 'Score': '10 points'}\n",
      "{'Title': 'Nobody ever paid me for code (bitecode.dev)', 'Link': 'https://www.bitecode.dev/p/nobody-ever-paid-me-for-code', 'Score': '108 points'}\n",
      "{'Title': 'Writing about what you learn pushes you to understand topics better (addyosmani.com)', 'Link': 'https://addyosmani.com/blog/write-learn/', 'Score': '349 points'}\n",
      "{'Title': 'Show HN: Little Rat – Chrome extension monitors network calls of all extensions (github.com/dnakov)', 'Link': None, 'Score': '14 points'}\n",
      "{'Title': 'Svix (YC W21) Is Hiring a Founding Account Executive (US Remote) (svix.com)', 'Link': None, 'Score': '0 points'}\n",
      "{'Title': 'Launch HN: Serra (YC S23) – Open-source, Python-based dbt alternative', 'Link': None, 'Score': '36 points'}\n",
      "{'Title': 'Bypassing YouTube video download throttling (0x7d0.dev)', 'Link': 'https://blog.0x7d0.dev/history/how-they-bypass-youtube-video-download-throttling/', 'Score': '269 points'}\n",
      "{'Title': 'Automatically classifying the content of sound files using ML (gingerbeardman.com)', 'Link': 'https://blog.gingerbeardman.com/2023/08/13/automatically-classifying-the-content-of-sound-files-using-ml/', 'Score': '9 points'}\n",
      "{'Title': 'Testing on production (marcochiappetta.medium.com)', 'Link': 'https://marcochiappetta.medium.com/yes-you-should-test-on-production-61f6dc61908b', 'Score': '112 points'}\n",
      "{'Title': 'A video game where you are an operating system (plbrault.com)', 'Link': 'https://plbrault.com/blog-posts/i-created-the-nerdierst-game-ever-en/', 'Score': '537 points'}\n",
      "{'Title': 'Python: Just Write SQL (joaodlf.com)', 'Link': 'https://joaodlf.com/python-just-write-sql', 'Score': '96 points'}\n",
      "{'Title': 'Police raid of a Kansas newsroom raises alarms about violations of press freedom (npr.org)', 'Link': 'https://www.npr.org/2023/08/14/1193676139/newspaper-marion-county-kansas-police-raid-first-amendment', 'Score': '114 points'}\n",
      "{'Title': 'Positive association between altitude and suicide in U.S. counties (nih.gov)', 'Link': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3114154/', 'Score': '33 points'}\n",
      "{'Title': \"I built a garbage collector for a language that doesn't need one (claytonwramsey.github.io)\", 'Link': 'https://claytonwramsey.github.io/2023/08/14/dumpster.html', 'Score': '8 points'}\n",
      "{'Title': 'Bomb threat causes mass evacuation at DEF CON hacking convention (theregister.com)', 'Link': 'https://www.theregister.com/2023/08/14/def_con_roundup/', 'Score': '26 points'}\n",
      "{'Title': 'Is Venus in some way tidally locked to Earth? (2020) (astronomy.stackexchange.com)', 'Link': 'https://astronomy.stackexchange.com/questions/36488/is-venus-in-some-way-tidally-locked-to-earth', 'Score': '79 points'}\n",
      "{'Title': 'Fediverse and Naive Bayes: The Grandfather of Spam Filters Still Making Waves (pixelfed.blog)', 'Link': 'https://pixelfed.blog/p/2023/feature/autospam-and-naive-bayes-the-grandfather-of-spam-filters-still-making-waves', 'Score': '93 points'}\n",
      "{'Title': 'Show HN: A website chatbot that also uses APIs (chatwith.tools)', 'Link': 'https://chatwith.tools', 'Score': '9 points'}\n",
      "{'Title': 'Things Unix can do atomically (2010) (rcrowley.org)', 'Link': 'https://rcrowley.org/2010/01/06/things-unix-can-do-atomically.html', 'Score': '119 points'}\n",
      "{'Title': 'Long live the King of Kings Accession ritual in ancient Persia (britishmuseum.org)', 'Link': 'https://www.britishmuseum.org/blog/long-live-king-kings-accession-ritual-ancient-persia', 'Score': '19 points'}\n",
      "{'Title': 'Veilid is an open-source, P2P, mobile-ﬁrst, networked application framework (veilid.com)', 'Link': 'https://veilid.com/', 'Score': '92 points'}\n",
      "{'Title': 'The world in which IPv6 was a good design (2017) (apenwarr.ca)', 'Link': 'https://apenwarr.ca/log/20170810', 'Score': '140 points'}\n",
      "{'Title': 'Risky Giant Steps Can Solve Optimization Problems Faster (quantamagazine.org)', 'Link': 'https://www.quantamagazine.org/risky-giant-steps-can-solve-optimization-problems-faster-20230811/', 'Score': '42 points'}\n",
      "{'Title': 'Momentum, a DIY 12-voice virtual analogue polyphonic synthesizer based on TSynth (electrotechnique.cc)', 'Link': 'http://electrotechnique.cc/Momentum.html', 'Score': '27 points'}\n",
      "{'Title': 'Semantic Code Reviews – Simple and direct comments without drama (m31coding.com)', 'Link': 'https://www.m31coding.com/blog/semantic-reviews.html', 'Score': '54 points'}\n",
      "{'Title': 'Azure ChatGPT: Private and secure ChatGPT for internal enterprise use (github.com/microsoft)', 'Link': None, 'Score': '808 points'}\n",
      "{'Title': 'Jitsi Meet Flutter SDK (jitsi.org)', 'Link': 'https://jitsi.org/blog/introducing-the-jitsi-meet-flutter-sdk/', 'Score': '161 points'}\n"
     ]
    }
   ],
   "source": [
    "# source: adpated from Broucke & Baessen (Chp. b9)\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# articles is an list that will hold info about each article \n",
    "articles = []\n",
    "\n",
    "url = 'http://news.ycombinator.com/news'\n",
    "r = requests.get(url)\n",
    "html_soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "# get all rows in news table\n",
    "for item in html_soup.find_all('tr', attrs = {'class':'athing'}):\n",
    "    \n",
    "    # scrape the title of each news \n",
    "    item_title = item.find('td', attrs = {'class':'title'}).find_next_sibling('td', attrs = {'class':'title'}).text\n",
    "    # find the hyperlink tag of each news\n",
    "    item_a = item.find('a', attrs = {'rel':'noreferrer'})\n",
    "    # extract href attribute from hyperlink tag\n",
    "    item_link = item_a.get('href') if item_a else None\n",
    "    # find the span tag with scores\n",
    "    item_score = item.find('span', attrs = {'class':'score'})\n",
    "    # find the row next to the above row and get scores\n",
    "    next_row = item.find_next_sibling('tr')\n",
    "    item_score = next_row.find('span', attrs = {'class':'score'})\n",
    "    item_score = item_score.get_text(strip = True) if item_score else '0 points'\n",
    "    \n",
    "    articles.append({\"Title\":item_title, \"Link\": item_link, \"Score\": item_score})\n",
    "    \n",
    "# append the article info \n",
    "for article in articles:\n",
    "    print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d4c575",
   "metadata": {},
   "source": [
    "2. Let's try to use the Hacker News API to scrape all the articles from the news website. We are using HTTP request to obtain the response from API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "74158900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "articles = []\n",
    "url = 'https://hacker-news.firebaseio.com/v0'\n",
    "\n",
    "# let's add the top stories element based on the API official document\n",
    "top_stories = requests.get(url + '/topstories.json').json()\n",
    "\n",
    "# see how many IDs we get\n",
    "print(len(top_stories))\n",
    "type(top_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9c054891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37121180, 37120874, 37120911, 37120372, 37120967]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are ids of the news\n",
    "top_stories[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53c5b7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://hacker-news.firebaseio.com/v0/item/37121180.json\n",
      "Fetching: https://hacker-news.firebaseio.com/v0/item/37120874.json\n",
      "Fetching: https://hacker-news.firebaseio.com/v0/item/37120911.json\n",
      "Fetching: https://hacker-news.firebaseio.com/v0/item/37120372.json\n",
      "Fetching: https://hacker-news.firebaseio.com/v0/item/37120967.json\n"
     ]
    }
   ],
   "source": [
    "for story_id in top_stories[:5]:\n",
    "    story_url = url + '/item/{}.json'.format(story_id)\n",
    "    print(\"Fetching:\", story_url)\n",
    "    \n",
    "    # make http request to each story URL\n",
    "    r = requests.get(story_url)\n",
    "    # your response is json-encoded\n",
    "    story_dict = r.json()\n",
    "    # store each story info in a list\n",
    "    articles.append(story_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "73790622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Software Engineering at Google https://abseil.io/resources/swe-book/html/toc.html 39\n",
      "Analysis of the data job market using HN job posts https://emiruz.com/post/2023-08-12-data-jobs/ 25\n",
      "How to run a miserable code review https://badsoftwareadvice.substack.com/p/how-to-run-a-miserable-code-review 16\n",
      "The 2002 Überlingen midair collision https://admiralcloudberg.medium.com/tears-in-the-rain-the-2002-%C3%BCberlingen-midair-collision-591232d0c51e 48\n",
      "I built a garbage collector for a language that doesn't need one https://claytonwramsey.github.io/2023/08/14/dumpster.html 13\n",
      "Writing about what you learn pushes you to understand topics better https://addyosmani.com/blog/write-learn/ 354\n",
      "Nobody ever paid me for code https://www.bitecode.dev/p/nobody-ever-paid-me-for-code 112\n",
      "Svix (YC W21) Is Hiring a Founding Account Executive (US Remote) https://www.svix.com/careers/ 1\n",
      "Show HN: Little Rat – Chrome extension monitors network calls of all extensions https://github.com/dnakov/little-rat 17\n",
      "Inside The Decline of Stack Exchange https://www.thediff.co/archive/inside-the-decline-of-stack-exchange/ 6\n"
     ]
    }
   ],
   "source": [
    "# display the key information you want\n",
    "for article in articles[:10]:\n",
    "    print(article['title'], article['url'], article['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed862f32",
   "metadata": {},
   "source": [
    "### How to retrieve the top 10 stories \n",
    "First method: query encoding in API requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b2b274af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37121180, 37120982, 37120874, 37120911, 37120967, 37120372, 37119942, 37118883, 37120715, 37108833]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url10 = 'https://hacker-news.firebaseio.com/v0/topstories.json?limitToFirst=10&orderBy=\"$key\"'\n",
    "ten_top_stories = requests.get(url10).json()\n",
    "print(ten_top_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1c1c596f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching:https://hacker-news.firebaseio.com/v0/item/37121180.json\n",
      "Fetching:https://hacker-news.firebaseio.com/v0/item/37120982.json\n",
      "Fetching:https://hacker-news.firebaseio.com/v0/item/37120874.json\n",
      "Fetching:https://hacker-news.firebaseio.com/v0/item/37120911.json\n",
      "Fetching:https://hacker-news.firebaseio.com/v0/item/37120967.json\n",
      "Fetching:https://hacker-news.firebaseio.com/v0/item/37120372.json\n",
      "Fetching:https://hacker-news.firebaseio.com/v0/item/37119942.json\n",
      "Fetching:https://hacker-news.firebaseio.com/v0/item/37118883.json\n",
      "Fetching:https://hacker-news.firebaseio.com/v0/item/37120715.json\n",
      "Fetching:https://hacker-news.firebaseio.com/v0/item/37108833.json\n"
     ]
    }
   ],
   "source": [
    "url = 'https://hacker-news.firebaseio.com/v0'\n",
    "articles = []\n",
    "\n",
    "for story_id in ten_top_stories:\n",
    "    \n",
    "    # create article link for each \n",
    "    story_url = url + '/item/{}.json'.format(story_id)\n",
    "    print('Fetching: ' + story_url)\n",
    "    \n",
    "    r = requests.get(story_url)\n",
    "    story_dict = r.json()\n",
    "    \n",
    "    articles.append(story_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2104490c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Software Engineering at Google https://abseil.io/resources/swe-book/html/toc.html 82\n",
      "Inside The Decline of Stack Exchange https://www.thediff.co/archive/inside-the-decline-of-stack-exchange/ 32\n",
      "Analysis of the data job market using HN job posts https://emiruz.com/post/2023-08-12-data-jobs/ 39\n",
      "How to run a miserable code review https://badsoftwareadvice.substack.com/p/how-to-run-a-miserable-code-review 25\n",
      "I built a garbage collector for a language that doesn’t need one https://claytonwramsey.github.io/2023/08/14/dumpster.html 30\n",
      "The 2002 Überlingen midair collision https://admiralcloudberg.medium.com/tears-in-the-rain-the-2002-%C3%BCberlingen-midair-collision-591232d0c51e 59\n",
      "Show HN: Little Rat – Chrome extension monitors network calls of all extensions https://github.com/dnakov/little-rat 31\n",
      "Writing about what you learn pushes you to understand topics better https://addyosmani.com/blog/write-learn/ 366\n",
      "Svix (YC W21) Is Hiring a Founding Account Executive (US Remote) https://www.svix.com/careers/ 1\n",
      "Nobody ever paid me for code https://www.bitecode.dev/p/nobody-ever-paid-me-for-code 115\n"
     ]
    }
   ],
   "source": [
    "# display the key information you want\n",
    "for article in articles:\n",
    "    print(article['title'], article['url'], article['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c07a90c",
   "metadata": {},
   "source": [
    "The other approach consists of defining a dict and pass it as a parameter\n",
    "   - this along with the headers allows to make a more specific request to an API\n",
    "   - it's recommended when developer key is needed \n",
    "   \n",
    "### Specific API requests\n",
    " \n",
    "- To make the API requests more specific, use headers and parameters in the request\n",
    "     - Headers\n",
    "     - Parameters are like filters to modify the scope of the request\n",
    "         - check API documentation\n",
    "         \n",
    "- Reddit API\n",
    "    - Scape the news in Reddit \n",
    "    - With a user-agent header \n",
    "    - Is the Reddit API free?\n",
    "        - Not all apps on Reddit will have to pay. The following conditions, effective as of June 1, enable free access to the data API: Apps that make fewer than 100 queries per minute using OAuth authentication and 10 queries per minute not using OAuth can use the API free of charge ([source](https://www.techtarget.com/whatis/feature/Reddit-pricing-API-charge-explained?Offer=abt_pubpro_AI-Insider)).\n",
    "     - Reddit API official document: https://www.reddit.com/dev/api/.\n",
    "     \n",
    "- Dealing with json:\n",
    "    - `pprint`: The pprint module in Python is a utility module that you can use to print data structures in a readable, pretty way. It's a part of the standard library that's especially useful for debugging code dealing with API requests, large JSON files, and data in general."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a99d7fb",
   "metadata": {},
   "source": [
    "1. Let's scrape the news in Reddit with API. \n",
    "\n",
    "    - http://www.reddit.com/r/news: The place for news articles about current events in the United States and the rest of the world.\n",
    "    \n",
    "    - http://www.reddit.com/r/Baruch: Baruch College's student run subreddit.\n",
    "\n",
    "Note: this example is adapted from this tutorial on [towardsdatascience](http://towardsdatascience.com/a-beginners-guide-to-accessing-data-withweb-apis-using-python-23d262181467)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9f2f91d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do I have to apply for TAP in order to apply for the Excelsior Program ?\n",
      "Does anyone know how long it takes Baruch to get CLEP scores?\n",
      "Thoughts on Jessica Webster for LIB 3030?\n",
      "Has anyone had Linda Dukette for Bus 9558? What's the course load for bus 9558 in general?\n",
      "just made my fall 2023 schedule! any feedback on these courses/professors?\n"
     ]
    }
   ],
   "source": [
    "# import the packages\n",
    "import requests, json\n",
    "\n",
    "payload = {\n",
    "    'limit': 5,\n",
    "    't': 'hot'}\n",
    "\n",
    "headers = {\n",
    "    'User-agent': 'Reddit bot 1.0'}\n",
    "\n",
    "endpoint = 'http://www.reddit.com/r/news/top.json'\n",
    "\n",
    "# can try other channel\n",
    "# endpoint = 'http://www.reddit.com/r/funny/top.json'\n",
    "endpoint = 'http://www.reddit.com/r/Baruch/new.json'\n",
    "\n",
    "r = requests.get(endpoint, headers = headers, params = payload)\n",
    "r_json = json.loads(r.content)\n",
    "\n",
    "# USE pprint to figure the hierarchy in json data\n",
    "# import pprint\n",
    "# pprint.pprint(r)\n",
    "\n",
    "# extract elements from json data\n",
    "for sub in (r_json['data']['children']):\n",
    "    title = sub['data']['title']\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bb097d1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "# pprint.pprint(r.json()['data']['children'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a472ec0",
   "metadata": {},
   "source": [
    "### Authenticatoin for News API\n",
    "\n",
    "News API is a simple HTTP REST (REpresentational State Transfer) API for searching and retrieving live articles from various sources\n",
    "\n",
    "REST means architectural constraints and here is an article aboout its components: https://restfulapi.net/.\n",
    "\n",
    "- Get your secret API key\n",
    "    - Go to: https://newsapi.org/docs/get-started\n",
    "\n",
    "\n",
    "- MY API key: [*****************************************]()\n",
    "    - Go to API_credentials.ipynb to find API id and sceret keys.\n",
    "    - You should apply one for yourself.\n",
    "\n",
    "\n",
    "- Read the terms of service: https://newsapi.org/terms\n",
    "    - Don't violate the use term\n",
    "    - attribution: The attribution should preferrably be a hyperlink to https://newsapi.org with the text \"Powered by News API\".\n",
    "    \n",
    "    \n",
    "- Since we do Python, we can use the Python client library: https://newsapi.org/docs/client-libraries/python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f449ff",
   "metadata": {},
   "source": [
    "#### Practice 1\n",
    "Now let's try to use Python client of news API to fetch news. Before getting on the code, you need to install `newsapi` package in Python.\n",
    "\n",
    "- Some users have issues with newsapi importing.\n",
    "- Try install `newsapi-python` and import the package with `from newsapi.newsapi_client import NewsApiClient`\n",
    "- This is recorded in GitHub issue [here](https://github.com/mattlisiv/newsapi-python/issues/29)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e81e7c7",
   "metadata": {},
   "source": [
    "We will use 2 main endpoints in News API:\n",
    "\n",
    "- Top headlines `/v2/top-headlines`: returns breaking news headlines for countries, categories, and singular publishers. This is perfect for use with news tickers or anywhere you want to use live up-to-date news headlines.\n",
    "\n",
    "\n",
    "- Everything `/v2/everything`: search every article published by over 80,000 different sources large and small in the last 5 years. This endpoint is ideal for news analysis and article discovery.\n",
    "\n",
    "\n",
    "- There is also a minor endpoint that can be used to retrieve a small subset of the publishers we can scan:\n",
    "    - Sources `/v2/top-headlines/sources`: returns information (including name, description, and category) about the most notable sources available for obtaining top headlines from. This list could be piped directly through to your users when showing them some of the options available.\n",
    "    \n",
    "Reference: https://newsapi.org/docs/endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ef8148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%cmd \n",
    "# pip install newsapi\n",
    "# pip install newsapi-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca2597dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsapi_key = '*****'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15c676b",
   "metadata": {},
   "source": [
    "1. Top headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "78375874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'entertainment-weekly',\n",
       " 'name': 'Entertainment Weekly',\n",
       " 'description': 'Online version of the print magazine includes entertainment news, interviews, reviews of music, film, TV and books, and a special area for magazine subscribers.',\n",
       " 'url': 'http://www.ew.com',\n",
       " 'category': 'entertainment',\n",
       " 'language': 'en',\n",
       " 'country': 'us'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# /v2/top-headlines/sources\n",
    "sources = newsapi.get_sources()\n",
    "\n",
    "# check sources of the news\n",
    "sources['sources'][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2a19c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from newsapi import NewsApiClient\n",
    "from newsapi.newsapi_client import NewsApiClient\n",
    "\n",
    "# Initialize\n",
    "newsapi = NewsApiClient(api_key= newsapi_key)\n",
    "\n",
    "# /v2/top-headlines\n",
    "top_headlines = newsapi.get_top_headlines(q='AI',\n",
    "                                          category='business',\n",
    "                                          language='en',\n",
    "                                          country='us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0bdb3651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': {'id': None, 'name': 'Mediaite'},\n",
       " 'author': None,\n",
       " 'title': 'Elon Musk Challenges Mark Zuckerberg to Fight at Facebook Chief’s House Tomorrow, Text Shows - Mediaite',\n",
       " 'description': \"In a screenshotted text sent to his biographer, Musk challenged Zuckerberg to an MMA fight on Monday. And he's even willing to cede the home octagon advantage.\",\n",
       " 'url': 'https://www.mediaite.com/sports/elon-musk-challenges-mark-zuckerberg-to-fight-at-facebook-chiefs-house-tomorrow-text-shows/',\n",
       " 'urlToImage': 'https://www.mediaite.com/wp-content/uploads/2023/07/Zuckerberg-and-Musk.jpg',\n",
       " 'publishedAt': '2023-08-13T15:48:00Z',\n",
       " 'content': None}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_headlines['articles'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88ca7e7",
   "metadata": {},
   "source": [
    "2. Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "58dd4c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /v2/everything\n",
    "all_articles = newsapi.get_everything(q='AI',\n",
    "                                      sources='bbc-news,the-verge',\n",
    "                                      domains='bbc.co.uk,techcrunch.com',\n",
    "                                      from_param='2023-08-01',\n",
    "                                      to='2023-08-13',\n",
    "                                      language='en',\n",
    "                                      sort_by='relevancy',\n",
    "                                      page=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f3898f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': {'id': 'techcrunch', 'name': 'TechCrunch'},\n",
       " 'author': 'Walter Thompson',\n",
       " 'title': 'TechCrunch+ Roundup: Creator economy VC survey, B2C fintech growth strategy, web3 demo day | TechCrunch',\n",
       " 'description': 'TechCrunch+ Roundup: Creator economy VC survey, B2C fintech growth strategy, web3 demo day | TechCrunchtechcrunch.com',\n",
       " 'url': 'https://techcrunch.com/2023/08/11/creator-economy-vc-survey-b2c-fintech-growth-strategy-web3-demo-day/',\n",
       " 'urlToImage': 'https://techcrunch.com/wp-content/uploads/2023/08/GettyImages-1586299819.jpg?resize=1200,800',\n",
       " 'publishedAt': '2023-08-11T16:59:21Z',\n",
       " 'content': 'There are a million reasons why startups fail, and there are only a few reasons why they succeed.\\r\\nAll successful startups share the same proof points, such as product-market fit, strong compounded g… [+6250 chars]'}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_articles['articles'][89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d98c76f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TechCrunch+ Roundup: Creator economy VC survey, B2C fintech growth strategy, web3 demo day | TechCrunch'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_articles['articles'][89]['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e74cee9",
   "metadata": {},
   "source": [
    "#### Practice 2\n",
    "Use JSON-based REST API for data requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "88cfc3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Maui fire: Search for victims intensifies after 80 deaths 57\n",
      "2 Watch: Onboard the boat bringing aid to fire devastated Maui 60\n",
      "3 Hawaii fires: Jason Momoa warns tourists not to visit Maui 58\n",
      "4 Ukraine war: Three-week-old baby and family among seven killed in Russian shelling 82\n",
      "5 New Zealand's youth vaping crisis clouds smoke-free future 58\n",
      "6 Miss Universe organisation cuts Indonesia ties over sex abuse claims 68\n",
      "7 Ecuador: Thousands of soldiers move gang leader Fito 52\n",
      "8 Perseid meteor shower lights up night sky 41\n",
      "9 Can this battery-swapping bike tech unchoke cities? We took a ride 66\n",
      "10 Watch: Thief suspect plucked from drain hiding spot 51\n"
     ]
    }
   ],
   "source": [
    "# Ex.4\n",
    "# source: https://www.geeksforgeeks.org/fetching-top-news-using-news-api/\n",
    "# BBC news api with authorization header and parameters\n",
    "\n",
    "import requests \n",
    "\n",
    "# headers to store the API key\n",
    "headers = {'Authorization': newsapi_key}\n",
    "\n",
    "query_params = {\n",
    "    \"source\": \"bbc-news\",\n",
    "    \"sortBy\": \"top\"}\n",
    "\n",
    "main_url = \" https://newsapi.org/v1/articles\"\n",
    " \n",
    "# fetching data in json format\n",
    "res = requests.get(main_url, headers = headers, params=query_params)\n",
    "open_bbc_page = res.json()\n",
    " \n",
    "# getting all articles in a string article\n",
    "articles = open_bbc_page[\"articles\"]\n",
    " \n",
    "# empty list to hold all trending news\n",
    "results = []\n",
    "     \n",
    "for article in articles:\n",
    "    results.append(article[\"title\"])\n",
    "\n",
    "# printing all trending news       \n",
    "for i in range(len(results)):            \n",
    "    print(i + 1, results[i], len(results[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be79a554",
   "metadata": {},
   "source": [
    "Same as the code below using Python client library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "175b8f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_headlines = newsapi.get_top_headlines(sources = 'bbc-news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3675381e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Watch: Onboard the boat bringing aid to fire devastated Maui',\n",
       " \"New Zealand's youth vaping crisis clouds smoke-free future\",\n",
       " 'Hawaii fires: Jason Momoa warns tourists not to visit Maui',\n",
       " 'Ukraine war: Three-week-old baby and family among seven killed in Russian shelling',\n",
       " 'Miss Universe organisation cuts Indonesia ties over sex abuse claims',\n",
       " 'Ecuador: Thousands of soldiers move gang leader Fito',\n",
       " 'Watch: Thief suspect plucked from drain hiding spot',\n",
       " 'Perseid meteor shower lights up night sky',\n",
       " 'Maui fire: Search for victims intensifies after 80 deaths',\n",
       " 'Can this battery-swapping bike tech unchoke cities? We took a ride']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[article['title'] for article in top_headlines['articles']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
